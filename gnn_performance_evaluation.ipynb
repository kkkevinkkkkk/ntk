{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2be09a2",
   "metadata": {},
   "source": [
    "# Experiment: Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b21728",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0938be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from models import GNNClassifier, GNNSim\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3b4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import util\n",
    "# graphs, _ = util.load_data(\"MUTAG\", degree_as_tag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f6ebf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "random_state = 1\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(random_state)\n",
    "# torch.cuda.manual_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "dataset_name = \"PROTEINS\"\n",
    "dataset_name = \"MUTAG\"\n",
    "path = os.path.join('./', 'data', 'TU')\n",
    "# dataset = TUDataset(path, name='MUTAG').shuffle()\n",
    "# dataset = TUDataset(path, name='MUTAG')\n",
    "dataset = TUDataset(path, name=dataset_name).shuffle()\n",
    "test_dataset = dataset[:len(dataset) // 10]\n",
    "train_dataset = dataset[len(dataset) // 10:]\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "labels = [data.y.item() for data in dataloader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ba93f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, train_loss: 0.7084, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 002, train_loss: 0.5835, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 003, train_loss: 0.5784, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 004, train_loss: 0.5640, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 005, train_loss: 0.5650, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 006, train_loss: 0.5634, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 007, train_loss: 0.5559, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 008, train_loss: 0.5542, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 009, train_loss: 0.5568, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 010, train_loss: 0.5565, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 011, train_loss: 0.5480, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 012, train_loss: 0.5479, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 013, train_loss: 0.5434, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 014, train_loss: 0.5439, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 015, train_loss: 0.5456, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 016, train_loss: 0.5508, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 017, train_loss: 0.5482, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 018, train_loss: 0.5422, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 019, train_loss: 0.5439, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 020, train_loss: 0.5390, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 021, train_loss: 0.5406, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 022, train_loss: 0.5343, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 023, train_loss: 0.5365, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 024, train_loss: 0.5287, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 025, train_loss: 0.5395, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 026, train_loss: 0.5324, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 027, train_loss: 0.5332, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 028, train_loss: 0.5355, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 029, train_loss: 0.5326, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 030, train_loss: 0.5254, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 031, train_loss: 0.5200, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 032, train_loss: 0.5275, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 033, train_loss: 0.5247, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 034, train_loss: 0.5128, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 035, train_loss: 0.5264, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 036, train_loss: 0.5229, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 037, train_loss: 0.5172, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 038, train_loss: 0.5237, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 039, train_loss: 0.5247, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 040, train_loss: 0.5181, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 041, train_loss: 0.5190, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 042, train_loss: 0.5071, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 043, train_loss: 0.5149, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 044, train_loss: 0.5106, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 045, train_loss: 0.5106, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 046, train_loss: 0.5212, train_acc: 0.6706, test_acc: 0.6111\n",
      "Epoch: 047, train_loss: 0.5082, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 048, train_loss: 0.4997, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 049, train_loss: 0.5096, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 050, train_loss: 0.5002, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 051, train_loss: 0.5017, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 052, train_loss: 0.5023, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 053, train_loss: 0.4941, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 054, train_loss: 0.5099, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 055, train_loss: 0.4888, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 056, train_loss: 0.4968, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 057, train_loss: 0.5021, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 058, train_loss: 0.4915, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 059, train_loss: 0.4919, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 060, train_loss: 0.4887, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 061, train_loss: 0.4912, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 062, train_loss: 0.4891, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 063, train_loss: 0.4808, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 064, train_loss: 0.4850, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 065, train_loss: 0.4897, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 066, train_loss: 0.4811, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 067, train_loss: 0.4912, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 068, train_loss: 0.4890, train_acc: 0.6765, test_acc: 0.6111\n",
      "Epoch: 069, train_loss: 0.4936, train_acc: 0.6941, test_acc: 0.6111\n",
      "Epoch: 070, train_loss: 0.4737, train_acc: 0.6824, test_acc: 0.6111\n",
      "Epoch: 071, train_loss: 0.4813, train_acc: 0.7000, test_acc: 0.5556\n",
      "Epoch: 072, train_loss: 0.4800, train_acc: 0.6941, test_acc: 0.6111\n",
      "Epoch: 073, train_loss: 0.4767, train_acc: 0.7000, test_acc: 0.5556\n",
      "Epoch: 074, train_loss: 0.4790, train_acc: 0.6882, test_acc: 0.6111\n",
      "Epoch: 075, train_loss: 0.4738, train_acc: 0.7059, test_acc: 0.6111\n",
      "Epoch: 076, train_loss: 0.4856, train_acc: 0.7118, test_acc: 0.6667\n",
      "Epoch: 077, train_loss: 0.4913, train_acc: 0.7176, test_acc: 0.7222\n",
      "Epoch: 078, train_loss: 0.4763, train_acc: 0.7353, test_acc: 0.7778\n",
      "Epoch: 079, train_loss: 0.4815, train_acc: 0.7353, test_acc: 0.7778\n",
      "Epoch: 080, train_loss: 0.4735, train_acc: 0.7529, test_acc: 0.7778\n",
      "Epoch: 081, train_loss: 0.4733, train_acc: 0.7529, test_acc: 0.7778\n",
      "Epoch: 082, train_loss: 0.4630, train_acc: 0.7529, test_acc: 0.7778\n",
      "Epoch: 083, train_loss: 0.4705, train_acc: 0.7529, test_acc: 0.7778\n",
      "Epoch: 084, train_loss: 0.4750, train_acc: 0.7588, test_acc: 0.7778\n",
      "Epoch: 085, train_loss: 0.4673, train_acc: 0.7588, test_acc: 0.7778\n",
      "Epoch: 086, train_loss: 0.4635, train_acc: 0.7529, test_acc: 0.7778\n",
      "Epoch: 087, train_loss: 0.4711, train_acc: 0.7588, test_acc: 0.7778\n",
      "Epoch: 088, train_loss: 0.4663, train_acc: 0.7588, test_acc: 0.7778\n",
      "Epoch: 089, train_loss: 0.4545, train_acc: 0.7588, test_acc: 0.7778\n",
      "Epoch: 090, train_loss: 0.4627, train_acc: 0.7588, test_acc: 0.7778\n",
      "Epoch: 091, train_loss: 0.4742, train_acc: 0.7647, test_acc: 0.7778\n",
      "Epoch: 092, train_loss: 0.4698, train_acc: 0.7765, test_acc: 0.7778\n",
      "Epoch: 093, train_loss: 0.4575, train_acc: 0.7765, test_acc: 0.7778\n",
      "Epoch: 094, train_loss: 0.4528, train_acc: 0.7765, test_acc: 0.7778\n",
      "Epoch: 095, train_loss: 0.4764, train_acc: 0.7765, test_acc: 0.7778\n",
      "Epoch: 096, train_loss: 0.4558, train_acc: 0.7765, test_acc: 0.7778\n",
      "Epoch: 097, train_loss: 0.4660, train_acc: 0.7706, test_acc: 0.7778\n",
      "Epoch: 098, train_loss: 0.4592, train_acc: 0.7706, test_acc: 0.7778\n",
      "Epoch: 099, train_loss: 0.4538, train_acc: 0.7706, test_acc: 0.7778\n",
      "Epoch: 100, train_loss: 0.4585, train_acc: 0.7706, test_acc: 0.7778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(model, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.get_loss(data)\n",
    "        loss.backward()\n",
    "        total_loss += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return total_loss / len(train_dataset)\n",
    "\n",
    "def test(model, dataloader, device):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "\n",
    "            data = data.to(device)\n",
    "            pred = model.predict(data).detach().cpu().numpy()\n",
    "\n",
    "            label = data.y.detach().cpu().numpy()\n",
    "            predictions.extend(pred)\n",
    "            labels.extend(label)\n",
    "    total_acc = accuracy_score(predictions, labels)\n",
    "    return total_acc\n",
    "    \n",
    "w = 32\n",
    "model_config = {}\n",
    "model_config[\"input_dim\"] = 7\n",
    "model_config[\"hidden_dim\"] = w\n",
    "model_config[\"output_dim\"] = w\n",
    "model_config[\"n_class\"] = 2\n",
    "model_config[\"c_u\"] = 1\n",
    "model_config[\"c_sigma\"] = 2\n",
    "model_config[\"num_layers\"] = 2\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "model = GNNClassifier(model_config)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model = model.to(device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(model, optimizer, train_dataloader, device)\n",
    "    train_acc = test(model, train_dataloader, device)\n",
    "    test_acc = test(model, test_dataloader, device)\n",
    "    print('Epoch: {:03d}, train_loss: {:.4f}, train_acc: {:.4f}, test_acc: {:.4f}'.format(epoch, train_loss, train_acc, test_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a471e",
   "metadata": {},
   "source": [
    "## Calculate finite gntk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6982252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 188/188 [00:00<00:00, 2634.53it/s]\n",
      "100%|████████████████████████████████████████| 188/188 [00:00<00:00, 823.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from models import clone_grads, paramdot\n",
    "import tqdm\n",
    "\n",
    "def normalize_matrix(matrix):\n",
    "    m = np.max(matrix)\n",
    "    out = matrix / m\n",
    "    return out\n",
    "def get_finite_ntk(model, dataloader):\n",
    "    grads = []\n",
    "    M = len(dataloader)\n",
    "    print(M)\n",
    "    i = 0\n",
    "\n",
    "    for data in tqdm.tqdm(dataloader):\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        loss =model(data)\n",
    "        loss.backward()\n",
    "        grads.append(clone_grads(model))\n",
    "    \n",
    "    finite_ntk = np.zeros((M,M))\n",
    "    for i in tqdm.tqdm(range(M)):\n",
    "        for j in range(i+1):\n",
    "            finite_ntk[i, j] = finite_ntk[j, i] = paramdot(grads[i], grads[j])\n",
    "    \n",
    "    return finite_ntk\n",
    "\n",
    "\n",
    "init_model = GNNSim(model_config)\n",
    "finite_ntk = get_finite_ntk(init_model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db08e82",
   "metadata": {},
   "source": [
    "## Calculate infinite gntk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d96c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from util import S2VGraph\n",
    "from kernels import calculate_inf_gntk\n",
    "from models import clone_grads, paramdot\n",
    "\n",
    "def map_dataloader_to_graphs(dataloader):\n",
    "    graphs = []\n",
    "    for data in dataloader:\n",
    "        g = nx.Graph()\n",
    "        label = data.y\n",
    "        node_tags = None\n",
    "        # add node\n",
    "        for j in range(data.x.shape[0]):\n",
    "            g.add_node(j)\n",
    "        # add edge\n",
    "        for i in range(data.edge_index.shape[-1]):\n",
    "            node_a, node_b = data.edge_index[0][i].item(), data.edge_index[1][i].item()\n",
    "            g.add_edge(node_a, node_b)\n",
    "        s2v_graph = S2VGraph(g, label, node_tags)\n",
    "        s2v_graph.node_features = data.x\n",
    "        graphs.append(s2v_graph)\n",
    "    \n",
    "    \n",
    "    for g in graphs:\n",
    "        g.neighbors = [[] for i in range(len(g.g))]\n",
    "        for i, j in g.g.edges():\n",
    "            g.neighbors[i].append(j)\n",
    "            g.neighbors[j].append(i)\n",
    "        degree_list = []\n",
    "        for i in range(len(g.g)):\n",
    "            g.neighbors[i] = g.neighbors[i]\n",
    "            degree_list.append(len(g.neighbors[i]))\n",
    "        g.max_neighbor = max(degree_list)\n",
    "\n",
    "    return graphs\n",
    "\n",
    "\n",
    "graphs = map_dataloader_to_graphs(dataloader)\n",
    "\n",
    "inf_ntk = calculate_inf_gntk(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9010c2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=500000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>normalized</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.860588</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046416</td>\n",
       "      <td>False</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.215443</td>\n",
       "      <td>False</td>\n",
       "      <td>0.908824</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915294</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.641589</td>\n",
       "      <td>False</td>\n",
       "      <td>0.927647</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.544347</td>\n",
       "      <td>False</td>\n",
       "      <td>0.937059</td>\n",
       "      <td>0.872222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.943529</td>\n",
       "      <td>0.855556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>464.158883</td>\n",
       "      <td>False</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.838889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2154.434690</td>\n",
       "      <td>False</td>\n",
       "      <td>0.748824</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.655882</td>\n",
       "      <td>0.644444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046416</td>\n",
       "      <td>True</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.215443</td>\n",
       "      <td>True</td>\n",
       "      <td>0.664706</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.677778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.641589</td>\n",
       "      <td>True</td>\n",
       "      <td>0.755294</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.544347</td>\n",
       "      <td>True</td>\n",
       "      <td>0.771176</td>\n",
       "      <td>0.761111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.830588</td>\n",
       "      <td>0.794444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>464.158883</td>\n",
       "      <td>True</td>\n",
       "      <td>0.877647</td>\n",
       "      <td>0.811111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2154.434690</td>\n",
       "      <td>True</td>\n",
       "      <td>0.920588</td>\n",
       "      <td>0.844444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.936471</td>\n",
       "      <td>0.844444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              C  normalized     train      test\n",
       "0      0.010000       False  0.860588  0.850000\n",
       "1      0.046416       False  0.882353  0.861111\n",
       "2      0.215443       False  0.908824  0.883333\n",
       "3      1.000000       False  0.915294  0.911111\n",
       "4      4.641589       False  0.927647  0.883333\n",
       "5     21.544347       False  0.937059  0.872222\n",
       "6    100.000000       False  0.943529  0.855556\n",
       "7    464.158883       False  0.910000  0.838889\n",
       "8   2154.434690       False  0.748824  0.694444\n",
       "9  10000.000000       False  0.655882  0.644444\n",
       "0      0.010000        True  0.664706  0.666667\n",
       "1      0.046416        True  0.664706  0.666667\n",
       "2      0.215443        True  0.664706  0.666667\n",
       "3      1.000000        True  0.676471  0.677778\n",
       "4      4.641589        True  0.755294  0.750000\n",
       "5     21.544347        True  0.771176  0.761111\n",
       "6    100.000000        True  0.830588  0.794444\n",
       "7    464.158883        True  0.877647  0.811111\n",
       "8   2154.434690        True  0.920588  0.844444\n",
       "9  10000.000000        True  0.936471  0.844444"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kernels import svc_search\n",
    "\n",
    "train_fold_idx = [np.loadtxt('dataset/{}/10fold_idx/train_idx-{}.txt'.format(\n",
    "        dataset_name, i)).astype(int) for i in range(1, 11)]\n",
    "test_fold_idx = [np.loadtxt('dataset/{}/10fold_idx/test_idx-{}.txt'.format(\n",
    "    dataset_name, i)).astype(int) for i in range(1, 11)]\n",
    "\n",
    "result_df = svc_search(finite_ntk, labels, train_fold_idx,test_fold_idx)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32bdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
